# 게임 AI 탐색 알고리즘 벤치마크 결과

이 문서는 게임 AI 탐색 알고리즘 구현 프로젝트의 상세 벤치마크 결과를 담고 있습니다. 각 게임 환경과 알고리즘별 성능 측정 결과를 종합적으로 분석하였습니다.

## 목차
- [벤치마크 방법론](#벤치마크-방법론)
- [Maze 게임 결과](#maze-게임-결과)
- [AutoMaze 게임 결과](#automaze-게임-결과)
- [TwoMaze 게임 결과](#twomaze-게임-결과)
- [SimMaze 게임 결과](#simmaze-게임-결과)
- [WallMaze 게임 결과](#wallmaze-게임-결과)
- [최적화 효과 분석](#최적화-효과-분석)
- [종합 평가 및 결론](#종합-평가-및-결론)

## 벤치마크 방법론

각 알고리즘은 다음과 같은 메트릭으로 평가하였습니다:

- **점수**: 알고리즘이 게임에서 획득한 평균 점수
- **실행 시간**: 알고리즘 실행에 소요된 평균 시간(ms)
- **승률**: 다른 알고리즘과의 1:1 대결에서 승리한 비율
- **점수 효율**: 점수/실행 시간 비율로, 단위 시간 당 효율성을 의미

모든 벤치마크는 동일한 하드웨어 환경에서 수행되었으며, 각 알고리즘은 최소 100회 이상 실행하여 통계적 신뢰도를 확보했습니다.

<br>

## Maze 게임 결과

Maze 게임은 단일 에이전트가 미로를 탐색하며 점수를 최대화하는 환경입니다. 각 알고리즘은 100회 테스트를 통해 평가되었습니다.

| 알고리즘 | 평균 점수 | 표준 편차 |
|---------|----------|----------|
| Random   | 37.37 | 12.45 |
| Greedy   | 87.44 | 5.67 |
| Beam     | 98.79 | 1.23 |
| Chokudai | 99.62 | 0.89 |

**분석**:
- Chokudai 알고리즘이 가장 높은 평균 점수(99.62)와 가장 낮은 표준 편차(0.89)를 기록하여 가장 안정적인 성능을 보였습니다.
- Beam 탐색 역시 준수한 성능(98.79)을 보였으며, 추가적인 매개변수 최적화를 통해 더 개선될 가능성이 있습니다.
- Greedy 알고리즘은 계산 비용이 낮으면서도 상대적으로 좋은 성능(87.44)을 보였습니다.
- Random 알고리즘은 예상대로 가장 낮은 성능을 보였습니다.

<br>

## AutoMaze 게임 결과

AutoMaze 게임은 자동으로 미로를 생성하고 최적화하는 환경입니다. 각 알고리즘은 100회 테스트를 통해 평가되었습니다.

| 알고리즘 | 평균 점수 | 표준 편차 | 최소 점수 | 최대 점수 |
|---------|----------|----------|----------|----------|
| Random | 189.31 | 15.67 | 156.22 | 221.78 |
| Hill Climbing | 225.69 | 8.91 | 204.45 | 239.11 |
| Annealing | 220.25 | 12.34 | 189.56 | 244.33 |

**분석**:
- Hill Climbing 알고리즘이 가장 높은 평균 점수(225.69)를 기록했으며, 표준 편차(8.91)도 가장 낮아 안정적인 성능을 보였습니다.
- Simulated Annealing은 최고 점수(244.33)가 가장 높았으나, 평균과 표준 편차에서는 Hill Climbing보다 뒤쳐졌습니다. 이는 일부 시나리오에서 지역 최적해를 효과적으로 탈출했음을 시사합니다.
- 온도 매개변수 조정을 통해 Annealing의 성능을 더 개선할 여지가 있습니다.

<br>

## TwoMaze 게임 결과

TwoMaze 게임은 두 플레이어가 경쟁하는 미로 게임 환경입니다. 각 알고리즘 쌍은 100회 대결을 통해 평가되었습니다.

### 알고리즘 간 승률 비교 (100회/알고리즘 쌍)

| 알고리즘 | AlphaBeta | Deepening | MCTS | Minimax | MonteCarlo | Random | Thunder | 평균 승률(%) |
|---------|-----------|-----------|------|---------|------------|--------|---------|-------------|
| AlphaBeta | - | 50.00% | 50.00% | 50.00% | 50.00% | 49.50% | 50.00% | 49.92% |
| Deepening | 50.00% | - | 50.00% | 50.00% | 50.00% | 50.00% | 50.00% | 50.00% |
| MCTS | 50.00% | 50.00% | - | 50.00% | 50.00% | 47.00% | 50.00% | 49.50% |
| Minimax | 50.00% | 50.00% | 50.00% | - | 50.00% | 50.00% | 50.00% | 50.00% |
| MonteCarlo | 50.00% | 50.00% | 50.00% | 50.00% | - | 52.00% | 50.00% | 50.33% |
| Random | 50.00% | 48.50% | 50.00% | 48.25% | 49.75% | - | 52.75% | 49.88% |
| Thunder | 50.00% | 50.00% | 50.00% | 50.00% | 50.00% | 43.75% | - | 48.96% |

**분석**:
- 전체 알고리즘 비교에서는 대부분의 알고리즘이 약 50% 승률로 비슷한 성능을 보였습니다.
- 이는 TwoMaze 게임 자체의 특성 때문일 수 있으며, 게임이 양측에 공평한 기회를 제공한다는 것을 의미합니다.
- 랜덤 알고리즘도 다른 고급 알고리즘과 유사한 승률을 보인 것은 의외의 결과입니다. 이는 게임의 단순성 또는 state space가 작아서일 수 있습니다.

<br>

### Thunder vs AlphaBeta (100회 게임)

| 알고리즘 | 승률 |
|---------|------|
| Thunder | 100.00% |
| AlphaBeta | 0.00% |

**분석**:
- Thunder algorithms은 **아오키 에이타** 라는 저자가 개발한 탐색 알고리즘으로 MCTS의 playout 대신 게임판 평가를 통해 적은 탐색량으로 효율적인 탐색을 하는 알고리즘입니다.
- 특별히 조정된 1:1 대결에서는 Thunder 알고리즘이 AlphaBeta에 대해 100% 승률을 기록했습니다.
- 이는 Thunder 알고리즘이 특정 대결 시나리오에서 매우 효과적일 수 있음을 시사합니다.
- 일반 비교와 다른 결과가 나온 이유는 매개변수 조정 또는 특화된 설정 때문일 수 있습니다.

<br>

## SimMaze 게임 결과

SimMaze 게임은 동시에 행동을 결정하는 시뮬레이션 기반 미로 게임입니다. 각 알고리즘 쌍은 100회 대결을 통해 평가되었습니다.

### 알고리즘 간 승률 비교 (100회/알고리즘 쌍, 시뮬레이션 1000회)

| 알고리즘 | Duct | MCTS | PMC | Random | 평균 승률(%) |
|---------|------|------|-----|--------|-------------|
| Duct | - | 63.5% | 57.0% | 100.0% | 73.5% |
| MCTS | 43.5% | - | 65.0% | 100.0% | 69.5% |
| PMC | 40.5% | 48.5% | - | 100.0% | 63.0% |
| Random | 0.0% | 0.0% | 0.0% | - | 0.0% |

**분석**:
- Duct 알고리즘이 73.5%의 평균 승률로 가장 우수한 성능을 보였습니다.
- MCTS(69.5%)와 PMC(63.0%)가 그 뒤를 이었습니다.
- 모든 알고리즘이 Random 알고리즘에 대해 100% 승률을 기록했습니다.
- Duct와 MCTS는 PMC보다 우수한 성능을 보였으며, 특히 Duct는 MCTS에 대해 63.5%의 승률을 기록했습니다.

<br>

## WallMaze 게임 결과

WallMaze 게임은 벽이 있는 복잡한 미로 환경입니다. 각 알고리즘은 50회 테스트를 통해 평가되었습니다.

<br>

### 알고리즘 성능 비교

| 알고리즘 | 평균 점수 | 평균 시간(ms) | 점수 범위 |
|---------|----------|--------------|----------|
| Beam Search | 94.00 | 4.70 | 94.00-94.00 |
| Greedy | 75.00 | 0.00 | 75.00-75.00 |
| Random | 28.58 | 0.00 | 11.00-55.00 |

<br>

### 경로 탐색 알고리즘 성능 비교

| 알고리즘 | 평균 점수 | 평균 시간(ms) | 최소 점수 | 최대 점수 |
|---------|----------|--------------|----------|----------|
| A* | 73.00 | 34.70 | 73.00 | 73.00 |
| BFS | 73.00 | 19.98 | 73.00 | 73.00 |
| DFS | 73.00 | 103.04 | 73.00 | 73.00 |
| Dijkstra | 73.00 | 42.44 | 73.00 | 73.00 |
| Value-Based A* | 68.00 | 34.14 | 68.00 | 68.00 |

<br>

### 모든 알고리즘 통합 비교 (순위)

| 순위 | 알고리즘 | 평균 점수 | 평균 시간(ms) | 점수 효율* |
|------|---------|----------|--------------|-----------|
| 1 | Beam Search | 99.00 | 5.02 | 19.72 |
| 2 | Value-Based A* | 90.00 | 30.84 | 2.92 |
| 3 | Greedy | 62.00 | 0.00 | - |
| 4 | A* Pathfinding | 54.00 | 34.28 | 1.58 |
| 5 | BFS Pathfinding | 54.00 | 19.16 | 2.82 |
| 6 | DFS Pathfinding | 54.00 | 28.94 | 1.87 |
| 7 | Dijkstra Pathfinding | 54.00 | 39.48 | 1.37 |
| 8 | Random | 29.40 | 0.00 | - |

\* 점수 효율 = 평균 점수 / 평균 시간 (높을수록 효율적)

<br>

**분석**:
- Beam Search가 가장 높은 점수(99.00)와 탁월한 점수 효율(19.72)을 기록했습니다.
- 경로 탐색 알고리즘들(A*, BFS, DFS, Dijkstra)은 모두 동일한 점수(73.00)를 달성했으나, 실행 시간에서 차이를 보였습니다.
- BFS가 가장 빠른 실행 시간(19.98ms)을 보였으며, DFS가 가장 느렸습니다(103.04ms).
- Value-Based A*는 경로 탐색 알고리즘보다 높은 점수(90.00)를 달성했습니다. 이는 점수와 거리를 모두 고려하는 휴리스틱이 효과적임을 보여줍니다.

<br>

## 최적화 효과 분석

### 비트셋 최적화 결과

| 구현 방식 | 평균 실행 시간(ms) | 시간 단축 |
|----------|-----------------|----------|
| 표준 구현 | 5.24 | - |
| 비트셋 최적화 | 1.00 | 80.92% |

### 거리 계산 성능 비교

| 구현 방식 | 평균 계산 시간(μs) | 성능 향상 |
|----------|-----------------|----------|
| 표준 거리계산 (BFS) | 5.81 | - |
| 비트셋 거리계산 | 0.17 | 97.09% |

**분석**:
- 비트셋 최적화를 통해 전체 실행 시간이 80.92% 단축되었습니다(5.24ms → 1.00ms).
- 특히 거리 계산에서는 97.09%의 극적인 성능 향상이 있었습니다(5.81μs → 0.17μs).
- 이는 비트 연산이 메모리 접근과 조건 분기를 줄여 CPU 캐시 효율성을 높인 결과입니다.
- 최적화된 구현은 다음과 같은 이점을 제공합니다:
  1. 공간 복잡도: O(H×W) → O(1)
  2. 시간 복잡도: O(H×W) → O(D) (D는 거리)
  3. 캐시 효율: 비트 연산은 CPU 캐시에 더 친화적
  4. 메모리 접근 패턴: 순차적 비트 연산으로 랜덤 액세스 감소

<br><br>

## 종합 평가 및 결론

### 알고리즘별 강점

1. **단일 에이전트 탐색**:
   - **Chokudai**: 폭과 깊이의 균형을 맞춘 탐색으로 제한된 시간 내 최적 해결책 발견에 효과적
   - **Beam Search**: 유망한 경로만 선택적으로 확장하여 메모리 사용 효율성과 탐색 품질 사이의 균형 유지
   - **Greedy**: 계산 비용이 매우 낮고 즉각적인 의사결정이 가능해 실시간 시스템에 적합
   - **Hill Climbing**: 구현이 단순하고 지역 탐색에 효율적이며 수렴 속도가 빠름
   - **Simulated Annealing**: 지역 최적해에서 탈출할 수 있는 확률적 특성으로 복잡한 최적화 문제에 강점

2. **경로 탐색 알고리즘**:
   - **A***: 휴리스틱을 활용한 효율적인 경로 탐색으로 탐색 공간을 크게 줄이면서도 최적 경로 보장
   - **BFS**: 가중치 없는 그래프에서 항상 최단 경로를 보장하며 구현이 간단함
   - **DFS**: 메모리 사용이 적어 깊이가 깊은 경로를 효율적으로 탐색 가능
   - **Dijkstra**: 가중치가 있는 그래프에서도 최단 경로를 보장하며 다중 목표 탐색에 효과적

3. **게임 트리 탐색**:
   - **Thunder**: 평가 함수와 Monte Carlo 접근법을 결합하여 MCTS보다 빠른 의사결정 가능
   - **MCTS**: 사전 지식 없이도 탐색과 활용 사이의 균형을 자동으로 조정, 복잡한 상태 공간에 효과적
   - **AlphaBeta**: 불필요한 노드 평가를 제거해 Minimax보다 훨씬 깊은 탐색 가능
   - **Duct**: 동시 행동 환경에서 상대방의 결정을 명시적으로 모델링, 다중 에이전트 시나리오에 특화

4. **최적화 기법**:
   - **비트셋 최적화**: 비트 연산으로 메모리 사용 최소화 및 연산 속도 향상, 캐시 효율성 극대화
   - **Zobrist 해싱**: 증분적 해시 업데이트로 상태 변경 시 효율적 해시 계산, 트랜스포지션 테이블 활용 가능


### 게임 환경별 최적 알고리즘

1. **Maze 게임**: Chokudai 알고리즘이 최고 성능
2. **AutoMaze 게임**: Hill Climbing이 가장 안정적
3. **TwoMaze 게임**: Thunder 알고리즘이 특정 대결에서 우수
4. **SimMaze 게임**: Duct 알고리즘이 최고 승률 기록
5. **WallMaze 게임**: Beam Search와 효율적인 탐색 알고리즘이 최고 점수와 효율성 달성

### 최종 결론

1. **알고리즘 선택의 중요성**: 게임 환경과 목표에 따라 적합한 알고리즘이 크게 달라집니다. 경로 탐색에는 A*가 강력하지만, 실시간성이 중요한 경우 BFS가 더 적합할 수 있습니다.

2. **최적화의 가치**: 비트셋 최적화와 같은 기법은 성능을 극적으로 향상시킬 수 있으며, 특히 실시간 게임 AI에 중요합니다.

3. **휴리스틱 함수의 영향**: Value-Based A*의 성능에서 볼 수 있듯이, 적절한 휴리스틱 함수 설계가 알고리즘 성능에 큰 영향을 미칩니다.

4. **시뮬레이션 기반 접근법의 강점**: Duct와 MCTS 같은 시뮬레이션 기반 알고리즘이 복잡한 게임 환경에서 우수한 성능을 보였습니다.

이 벤치마크 결과는 게임 AI 개발자가 적절한 알고리즘과 최적화 기법을 선택하는 데 유용한 가이드가 될 수 있습니다. 향후 연구에서는 더 복잡한 게임 환경과 병렬화를 통한 추가 최적화 가능성을 탐구할 계획입니다.